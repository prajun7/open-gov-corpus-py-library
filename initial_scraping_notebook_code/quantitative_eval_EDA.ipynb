{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84754c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "482ac7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Benchmark Results EDA Script ---\n",
      "\n",
      "--- Generating comparison charts ---\n",
      "\n",
      "--- Performance Summary ---\n",
      "Metric: F1\n",
      "  - Best Performer: meta-llama/llama-3.1-70b-instruct (Avg Score: 0.3389)\n",
      "  - Worst Performer: mistralai/mistral-7b-instruct-v0.3 (Avg Score: 0.2444)\n",
      "Metric: CosineSim\n",
      "  - Best Performer: qwen/qwen-2.5-72b-instruct (Avg Score: 0.7792)\n",
      "  - Worst Performer: meta-llama/llama-3.1-8b-instruct (Avg Score: 0.7171)\n",
      "Metric: BERTScore\n",
      "  - Best Performer: qwen/qwen-2.5-72b-instruct (Avg Score: 0.8904)\n",
      "  - Worst Performer: meta-llama/llama-3.1-8b-instruct (Avg Score: 0.8656)\n",
      "\n",
      "Performance summary saved to 'benchmark_eda_charts/performance_summary.txt'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/q4flhk7d5gl31398vk4_449c0000gn/T/ipykernel_75948/2136976727.py:69: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x='Score', y='Model', data=metric_data, estimator='mean', errorbar=None, palette='viridis', orient='h')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Saved average score chart to 'benchmark_eda_charts/1_avg_f1_comparison.png'\n",
      "  - Saved score distribution chart to 'benchmark_eda_charts/2_dist_f1_comparison.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/q4flhk7d5gl31398vk4_449c0000gn/T/ipykernel_75948/2136976727.py:82: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.boxplot(x='Score', y='Model', data=metric_data, palette='plasma', orient='h')\n",
      "/var/folders/gy/q4flhk7d5gl31398vk4_449c0000gn/T/ipykernel_75948/2136976727.py:69: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x='Score', y='Model', data=metric_data, estimator='mean', errorbar=None, palette='viridis', orient='h')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Saved average score chart to 'benchmark_eda_charts/1_avg_cosinesim_comparison.png'\n",
      "  - Saved score distribution chart to 'benchmark_eda_charts/2_dist_cosinesim_comparison.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/q4flhk7d5gl31398vk4_449c0000gn/T/ipykernel_75948/2136976727.py:82: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.boxplot(x='Score', y='Model', data=metric_data, palette='plasma', orient='h')\n",
      "/var/folders/gy/q4flhk7d5gl31398vk4_449c0000gn/T/ipykernel_75948/2136976727.py:69: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x='Score', y='Model', data=metric_data, estimator='mean', errorbar=None, palette='viridis', orient='h')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Saved average score chart to 'benchmark_eda_charts/1_avg_bertscore_comparison.png'\n",
      "  - Saved score distribution chart to 'benchmark_eda_charts/2_dist_bertscore_comparison.png'\n",
      "\n",
      "--- EDA Script Finished ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/q4flhk7d5gl31398vk4_449c0000gn/T/ipykernel_75948/2136976727.py:82: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.boxplot(x='Score', y='Model', data=metric_data, palette='plasma', orient='h')\n"
     ]
    }
   ],
   "source": [
    "# Config\n",
    "INPUT_FILE = \"benchmark_scores.csv\"\n",
    "OUTPUT_DIR = \"benchmark_eda_charts\"\n",
    "\n",
    "# Generates and saves bar charts and box plots to compare model scores.\n",
    "def create_comparison_charts(df):\n",
    "    print(\"\\n--- Generating comparison charts ---\")\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    if not os.path.exists(OUTPUT_DIR):\n",
    "        os.makedirs(OUTPUT_DIR)\n",
    "        \n",
    "    # Identify the base model names from the columns\n",
    "    model_name_map = {\n",
    "        col: col.replace('Answer_', '').replace('_', '/') \n",
    "        for col in df.columns if col.startswith('Answer_') and not any(k in col for k in ['_F1', '_CosineSim', '_BERTScore'])\n",
    "    }\n",
    "    \n",
    "    if not model_name_map:\n",
    "        print(\"Error: No model answer columns found. Cannot generate charts.\")\n",
    "        return\n",
    "\n",
    "    # Reshape data for easier plotting\n",
    "    # We want to \"melt\" the dataframe from a wide format to a long format.\n",
    "    id_vars = ['Question', 'Answer']\n",
    "    value_vars = [f\"{prefix}_{metric}\" for prefix in model_name_map.keys() for metric in ['F1', 'CosineSim', 'BERTScore']]\n",
    "    \n",
    "    long_df = pd.melt(df, id_vars=id_vars, value_vars=value_vars, var_name='MetricType', value_name='Score')\n",
    "    \n",
    "    # Split 'MetricType' into 'Model' and 'Metric'\n",
    "    long_df[['Model', 'Metric']] = long_df['MetricType'].str.rsplit('_', n=1, expand=True)\n",
    "    long_df['Model'] = long_df['Model'].map({k.replace('/', '_'): v for k, v in model_name_map.items()}) # Clean up model names\n",
    "\n",
    "    # Calculate and print best/worst performers\n",
    "    summary_lines = [\"--- Performance Summary ---\"]\n",
    "    metrics_to_analyze = ['F1', 'CosineSim', 'BERTScore']\n",
    "    for metric in metrics_to_analyze:\n",
    "        metric_data = long_df[long_df['Metric'] == metric]\n",
    "        avg_scores = metric_data.groupby('Model')['Score'].mean()\n",
    "        \n",
    "        best_model = avg_scores.idxmax()\n",
    "        worst_model = avg_scores.idxmin()\n",
    "        \n",
    "        summary_lines.append(f\"Metric: {metric}\")\n",
    "        summary_lines.append(f\"  - Best Performer: {best_model} (Avg Score: {avg_scores.max():.4f})\")\n",
    "        summary_lines.append(f\"  - Worst Performer: {worst_model} (Avg Score: {avg_scores.min():.4f})\")\n",
    "    \n",
    "    summary_text = \"\\n\".join(summary_lines)\n",
    "    print(f\"\\n{summary_text}\\n\")\n",
    "\n",
    "    # Save the summary to a text file \n",
    "    summary_filepath = os.path.join(OUTPUT_DIR, \"performance_summary.txt\")\n",
    "    try:\n",
    "        with open(summary_filepath, 'w', encoding='utf-8') as f:\n",
    "            f.write(summary_text)\n",
    "        print(f\"Performance summary saved to '{summary_filepath}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving performance summary: {e}\")\n",
    "    \n",
    "    # Generate charts\n",
    "    metrics_to_plot = ['F1', 'CosineSim', 'BERTScore']\n",
    "    \n",
    "    for metric in metrics_to_plot:\n",
    "        metric_data = long_df[long_df['Metric'] == metric]\n",
    "        \n",
    "        # Bar chart for avg scores\n",
    "        plt.style.use('seaborn-v0_8-whitegrid')\n",
    "        plt.figure(figsize=(12, 7))\n",
    "        sns.barplot(x='Score', y='Model', data=metric_data, estimator='mean', errorbar=None, palette='viridis', orient='h')\n",
    "        plt.title(f'Average {metric} Across Models', fontsize=16, weight='bold')\n",
    "        plt.xlabel(f'Average Score', fontsize=12)\n",
    "        plt.ylabel('Model', fontsize=12)\n",
    "        plt.xlim(0, 1) # Scores are between 0 and 1\n",
    "        plt.tight_layout()\n",
    "        chart_path = os.path.join(OUTPUT_DIR, f\"1_avg_{metric.lower()}_comparison.png\")\n",
    "        plt.savefig(chart_path, dpi=300)\n",
    "        plt.close()\n",
    "        print(f\"  - Saved average score chart to '{chart_path}'\")\n",
    "        \n",
    "        # box Plot for score distribution\n",
    "        plt.figure(figsize=(12, 7))\n",
    "        sns.boxplot(x='Score', y='Model', data=metric_data, palette='plasma', orient='h')\n",
    "        plt.title(f'Distribution of {metric} Scores Across Models', fontsize=16, weight='bold')\n",
    "        plt.xlabel('Score', fontsize=12)\n",
    "        plt.ylabel('Model', fontsize=12)\n",
    "        plt.xlim(0, 1)\n",
    "        plt.tight_layout()\n",
    "        chart_path = os.path.join(OUTPUT_DIR, f\"2_dist_{metric.lower()}_comparison.png\")\n",
    "        plt.savefig(chart_path, dpi=300)\n",
    "        plt.close()\n",
    "        print(f\"  - Saved score distribution chart to '{chart_path}'\")\n",
    "\n",
    "# Main function to run the EDA on benchmark results.\n",
    "def main():\n",
    "    print(\"--- Starting Benchmark Results EDA Script ---\")\n",
    "    \n",
    "    if not os.path.exists(INPUT_FILE):\n",
    "        print(f\"FATAL ERROR: Input file not found at '{INPUT_FILE}'\")\n",
    "        return\n",
    "        \n",
    "    try:\n",
    "        df = pd.read_csv(INPUT_FILE)\n",
    "        create_comparison_charts(df)\n",
    "        print(\"\\n--- EDA Script Finished ---\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
